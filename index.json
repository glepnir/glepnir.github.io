[{"categories":[],"contents":"Last week, I was staring at two pieces of code a friend had sent me, asking which one I preferred. They looked like this:\n// Version A double calculate_mean(const vector\u0026lt;double\u0026gt;\u0026amp; data) { double sum = 0.0; for (const auto\u0026amp; x : data) { sum += x; } return sum / data.size(); } // Version B double calculate_stddev(const vector\u0026lt;double\u0026gt;\u0026amp; data) { double sum = 0.0; double mean = calculate_mean(data); for (const auto\u0026amp; x : data) { sum += (x - mean) * (x - mean); } return sqrt(sum / data.size()); } I looked at them for a solid five seconds before it hit me: these two loops were fundamentally the same mathematical pattern! But in the code, that pattern was buried under for loops and accumulation variables.\nSeeing with Math Eyes In math, we\u0026rsquo;d write these calculations as:\nmean=1n‚àëi=1nxi \\text{mean} = \\frac{1}{n} \\sum_{i=1}^n x_i mean=n1‚Äãi=1‚àën‚Äãxi‚Äãstddev=1n‚àëi=1n(xi‚àíŒº)2 \\text{stddev} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\mu)^2} stddev=n1‚Äãi=1‚àën‚Äã(xi‚Äã‚àíŒº)2‚ÄãSee that $\\sum$ symbol? That\u0026rsquo;s our abstraction point. In functional programming, this is called a fold (or reduce), defined as:\nfold(f,z,[x1,x2,...,xn])=f(f(f(z,x1),x2),...,xn) \\text{fold}(f, z, [x_1, x_2, ..., x_n]) = f(f(f(z, x_1), x_2), ..., x_n) fold(f,z,[x1‚Äã,x2‚Äã,...,xn‚Äã])=f(f(f(z,x1‚Äã),x2‚Äã),...,xn‚Äã)Looking at my code with this new perspective:\ntemplate\u0026lt;typename T, typename BinaryOp\u0026gt; T fold(const vector\u0026lt;T\u0026gt;\u0026amp; vec, T init, BinaryOp op) { T result = init; for (const auto\u0026amp; x : vec) { result = op(result, x); } return result; } Now both calculations become:\ndouble mean = fold(data, 0.0, plus\u0026lt;double\u0026gt;{}) / data.size(); double variance = fold(data, 0.0, [mean](double acc, double x) { return acc + (x - mean) * (x - mean); }) / data.size(); The Real Breakthrough: Seeing Deeper Patterns I started noticing this pattern everywhere. Take this convex hull algorithm I\u0026rsquo;d written:\nvector\u0026lt;Point\u0026gt; find_convex_hull(const vector\u0026lt;Point\u0026gt;\u0026amp; points) { vector\u0026lt;Point\u0026gt; hull; for (size_t i = 0; i \u0026lt; points.size(); ++i) { for (size_t j = 0; j \u0026lt; points.size(); ++j) { if (i == j) continue; bool all_on_same_side = true; for (size_t k = 0; k \u0026lt; points.size(); ++k) { if (k == i || k == j) continue; if (!is_on_same_side(points[i], points[j], points[k])) { all_on_same_side = false; break; } } if (all_on_same_side) { hull.push_back(points[i]); hull.push_back(points[j]); } } } return remove_duplicates(hull); } Three nested loops! But with functional thinking, I saw predicate logic:\nA point pair (i,j) belongs to the convex hull boundary if and only if all other points are on the same side of the line segment (i,j).\nMathematically: (i,j)‚ààhull‚ÄÖ‚ü∫‚ÄÖ‚àÄk‚â†i,j:same_side(i,j,k) (i,j) \\in \\text{hull} \\iff \\forall k \\neq i,j : \\text{same\\_side}(i,j,k) (i,j)‚ààhull‚ü∫‚àÄkÓÄ†=i,j:same_side(i,j,k)In C++, this becomes:\nvector\u0026lt;Point\u0026gt; find_convex_hull_fp(const vector\u0026lt;Point\u0026gt;\u0026amp; points) { auto pairs = cartesian_product(points, points); auto is_hull_edge = [\u0026amp;](const pair\u0026lt;Point, Point\u0026gt;\u0026amp; edge) { return all_of(points.begin(), points.end(), [\u0026amp;](const Point\u0026amp; p) { return \u0026amp;p == \u0026amp;edge.first || \u0026amp;p == \u0026amp;edge.second || is_on_same_side(edge.first, edge.second, p); }); }; return filter(pairs, is_hull_edge) | transform([](auto\u0026amp;\u0026amp; p) { return vector{p.first, p.second}; }) | flatten() | unique(); } Why This Matters: You Can Actually Prove Things Here\u0026rsquo;s the cool part: functional code is easier to reason about.\nWith the original code, proving correctness meant:\nTracking three loop variables Understanding when the break happens Verifying when hull gets updated With the functional version:\ncartesian_product generates all point pairs (obvious) is_hull_edge is a direct translation of the mathematical definition The composition uses standard, well-understood operations I can even write tests that verify mathematical properties:\n// Convex hull property: all points should be inside the hull TEST(ConvexHull, AllPointsInsideHull) { auto points = generate_random_points(100); auto hull = find_convex_hull_fp(points); for (const auto\u0026amp; p : points) { ASSERT_TRUE(is_point_inside_convex_polygon(p, hull)); } } Category Theory Sneaks In Recently, I was writing a config parser with multiple operations that could fail:\noptional\u0026lt;int\u0026gt; parse_timeout(const string\u0026amp; str); optional\u0026lt;string\u0026gt; parse_hostname(const string\u0026amp; str); optional\u0026lt;Config\u0026gt; create_config(int timeout, const string\u0026amp; host); The traditional way:\noptional\u0026lt;Config\u0026gt; parse_config(const string\u0026amp; timeout_str, const string\u0026amp; host_str) { auto timeout = parse_timeout(timeout_str); if (!timeout) return nullopt; auto host = parse_hostname(host_str); if (!host) return nullopt; return create_config(*timeout, *host); } The functional way uses a pattern (some people call it a monad, but I just call it useful):\ntemplate\u0026lt;typename T, typename Func\u0026gt; auto and_then(const optional\u0026lt;T\u0026gt;\u0026amp; opt, Func f) -\u0026gt; decltype(f(opt.value())) { if (!opt) return decltype(f(opt.value()))(); return f(*opt); } optional\u0026lt;Config\u0026gt; parse_config_fp(const string\u0026amp; timeout_str, const string\u0026amp; host_str) { return and_then(parse_timeout(timeout_str), [\u0026amp;](int timeout) { return and_then(parse_hostname(host_str), [\u0026amp;](const string\u0026amp; host) { return create_config(timeout, host); }); }); } Mathematically, this is composition in the Kleisli category: f:A‚ÜíM(B),g:B‚ÜíM(C)g‚àòKf:A‚ÜíM(C) f: A \\to M(B), \\quad g: B \\to M(C) \\\\ g \\circ_K f: A \\to M(C) f:A‚ÜíM(B),g:B‚ÜíM(C)g‚àòK‚Äãf:A‚ÜíM(C)Performance? Actually Better People say functional code is slow. Modern C++ compilers are smart:\n// Hand-written \u0026#34;optimized\u0026#34; version double sum_squares(const vector\u0026lt;double\u0026gt;\u0026amp; data) { double sum = 0.0; for (const auto\u0026amp; x : data) { sum += x * x; } return sum; } // Functional version double sum_squares_fp(const vector\u0026lt;double\u0026gt;\u0026amp; data) { return fold(data, 0.0, [](double acc, double x) { return acc + x * x; }); } With -O3, GCC generates identical assembly for both. The functional version is actually safer‚Äîno loop variables, no bounds checking worries.\nMy New Toolkit Here\u0026rsquo;s what functional thinking added to my C++ toolbox:\nmap/filter/reduce - The basics for working with collections Function composition - compose(f, g)(x) = f(g(x)) Currying - curry(f)(a)(b) = f(a, b) Lazy evaluation - Using generator or ranges::view Like currying for configuration:\nauto create_server = curry([](int port, const string\u0026amp; host, Config config) { return Server{port, host, config}; }); auto create_local_server = create_server(8080, \u0026#34;localhost\u0026#34;); auto server = create_local_server(config); The Mindset Shift Functional programming taught me something important: code is math, and the compiler is my proof assistant.\nBefore: I wrote loops thinking \u0026ldquo;do this repeatedly\u0026rdquo;. Now: I write fold thinking \u0026ldquo;apply this associative operation\u0026rdquo;.\nBefore: I wrote conditionals thinking \u0026ldquo;if this, then that\u0026rdquo;. Now: I write filter thinking \u0026ldquo;select elements satisfying this predicate\u0026rdquo;.\nThis mindset lets me write code that\u0026rsquo;s easier to prove correct. Last week I found a bug and mentally traced it:\nGiven: filter(is_even, [1,2,3,4]) = [2,4] Given: map(square, [2,4]) = [4,16] Given: fold(add, 0, [4,16]) = 20 Therefore: sum of squares of even numbers = 20 Writing it down like that was the proof.\nFunctional C++ in the Real World This is how I write production code now:\n// HTTP request processing pipeline auto handle_request = compose( validate_request, authenticate, parse_body\u0026lt;Order\u0026gt;, process_order, create_response ); // Or with ranges auto valid_orders = requests | views::filter(is_valid_order) | views::transform(parse_order) | views::filter([](const Order\u0026amp; o) { return o.total \u0026gt; 100.0; }) | views::transform(apply_discount) | ranges::to\u0026lt;vector\u0026gt;(); This isn\u0026rsquo;t \u0026ldquo;functional C++\u0026quot;‚Äîit\u0026rsquo;s just C++. But it\u0026rsquo;s C++ written with functional thinking.\nFinally When I started seeing loops through mathematical eyes, they stopped being loops and became instances of algebraic structures. That perspective lets me write code that\u0026rsquo;s cleaner, more correct, and honestly more fun to write.\nMaybe that\u0026rsquo;s the end goal of programming: code stops being instructions and becomes executable mathematics.\n","date":"2025-12-27","permalink":"https://www.functor.me/posts/thought_fp/","section":"","summary":"","tags":[],"title":"When Loops Become Math: How Functional Thinking Changed My C++"},{"categories":[],"contents":"For years, I was stuck in this cycle: find something that looks decent, tweak HSL values until it \u0026ldquo;feels right,\u0026rdquo; use it for a few weeks, then get that creeping eye strain. Suddenly colors that looked fine before would start to irritate me. Back to the drawing board.\nI must have done this dozens of times. Each round felt more arbitrary than the last‚Äîjust moving sliders around hoping something would click. Honestly, it was getting ridiculous. Why couldn\u0026rsquo;t I just find something that worked and stick with it?\nThen one night, while adjusting my umpteenth orange hue, it hit me: people have been studying vision for decades. There\u0026rsquo;s actual science about how we see color, what causes eye strain, how to make things readable. Maybe instead of guessing, I could actually, you know, use that science.\nSo I did. And it turns out, building a theme from first principles works way better than tweaking hex codes.\nPart 1: Your Color Picker is Probably Lying to You Here\u0026rsquo;s the thing no one tells you: RGB and HSL are kind of broken for designing themes. They make sense to computers but not to human eyes. In RGB, the \u0026ldquo;distance\u0026rdquo; between colors has nothing to do with how different they actually look. HSL is slightly better, but still weird‚Äîchanging saturation can make some colors get much brighter while others barely change.\nIt\u0026rsquo;s like trying to measure temperature with a ruler. You\u0026rsquo;re using the wrong tool for the job.\nEnter Oklab: A Color Space That Actually Makes Sense After digging around, I found something called Oklab. It\u0026rsquo;s a \u0026ldquo;perceptually uniform\u0026rdquo; color space, which is a fancy way of saying: if you move a color 10 units in Oklab, it looks about 10 units different to your eyes. No surprises.\nThe math goes something like this:\nStep 1: Oklab ‚Üí LMS (how your eye\u0026rsquo;s cones respond) [lms]=[10.39630.21581‚àí0.1056‚àí0.06391‚àí0.0895‚àí1.2915][Lab] \\begin{bmatrix} l \\\\ m \\\\ s \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; 0.3963 \u0026amp; 0.2158 \\\\ 1 \u0026amp; -0.1056 \u0026amp; -0.0639 \\\\ 1 \u0026amp; -0.0895 \u0026amp; -1.2915 \\end{bmatrix} \\begin{bmatrix} L \\\\ a \\\\ b \\end{bmatrix} ‚Äãlms‚Äã‚Äã=‚Äã111‚Äã0.3963‚àí0.1056‚àí0.0895‚Äã0.2158‚àí0.0639‚àí1.2915‚Äã‚Äã‚ÄãLab‚Äã‚ÄãStep 2: Inverse cube root LMSlinear=[l3,m3,s3]T \\text{LMS}_{\\text{linear}} = [l^3, m^3, s^3]^T LMSlinear‚Äã=[l3,m3,s3]TStep 3: LMS ‚Üí Linear RGB [RGB]=[4.0767‚àí3.30770.2310‚àí1.26842.6098‚àí0.3413‚àí0.0042‚àí0.70341.7076][l3m3s3] \\begin{bmatrix} R \\\\ G \\\\ B \\end{bmatrix} = \\begin{bmatrix} 4.0767 \u0026amp; -3.3077 \u0026amp; 0.2310 \\\\ -1.2684 \u0026amp; 2.6098 \u0026amp; -0.3413 \\\\ -0.0042 \u0026amp; -0.7034 \u0026amp; 1.7076 \\end{bmatrix} \\begin{bmatrix} l^3 \\\\ m^3 \\\\ s^3 \\end{bmatrix} ‚ÄãRGB‚Äã‚Äã=‚Äã4.0767‚àí1.2684‚àí0.0042‚Äã‚àí3.30772.6098‚àí0.7034‚Äã0.2310‚àí0.34131.7076‚Äã‚Äã‚Äãl3m3s3‚Äã‚ÄãStep 4: Gamma correction (sRGB) CsRGB={12.92√óClinearif¬†Clinear‚â§0.00313081.055√óClinear1/2.4‚àí0.055otherwise C_{\\text{sRGB}} = \\begin{cases} 12.92 \\times C_{\\text{linear}} \u0026amp; \\text{if } C_{\\text{linear}} \\leq 0.0031308 \\\\ 1.055 \\times C_{\\text{linear}}^{1/2.4} - 0.055 \u0026amp; \\text{otherwise} \\end{cases} CsRGB‚Äã={12.92√óClinear‚Äã1.055√óClinear1/2.4‚Äã‚àí0.055‚Äãif¬†Clinear‚Äã‚â§0.0031308otherwise‚ÄãYeah, that looks intimidating. But here\u0026rsquo;s the Lua code that makes it usable:\nlocal function oklab_to_linear_rgb(L, a, b) -- Oklab to LMS local l = L + 0.3963377774 * a + 0.2158037573 * b local m = L - 0.1055613458 * a - 0.0638541728 * b local s = L - 0.0894841775 * a - 1.2914855480 * b -- Inverse cube root local l3, m3, s3 = l * l * l, m * m * m, s * s * s -- LMS to linear RGB local r = 4.0767416621 * l3 - 3.3077115913 * m3 + 0.2309699292 * s3 local g = -1.2684380046 * l3 + 2.6097574011 * m3 - 0.3413193965 * s3 local b_out = -0.0041960863 * l3 - 0.7034186147 * m3 + 1.7076147010 * s3 return r, g, b_out end local function linear_to_srgb_component(c) -- Gamma correction if c \u0026lt;= 0.0031308 then return c * 12.92 else return 1.055 * (c ^ (1 / 2.4)) - 0.055 end end local function oklab_to_srgb(L, a, b) local r, g, b_comp = oklab_to_linear_rgb(L, a, b) r = linear_to_srgb_component(r) g = linear_to_srgb_component(g) b_comp = linear_to_srgb_component(b_comp) -- Clamp and convert to hex r = math.floor(math.max(0, math.min(1, r)) * 255 + 0.5) g = math.floor(math.max(0, math.min(1, g)) * 255 + 0.5) b_comp = math.floor(math.max(0, math.min(1, b_comp)) * 255 + 0.5) return string.format(\u0026#39;#%02x%02x%02x\u0026#39;, r, g, b_comp) end The cool part? Now instead of this:\n-- Random hex code I found somewhere local orange = \u0026#34;#c5895b\u0026#34; I can do this:\n-- \u0026#34;I want a color that\u0026#39;s 68% bright, slightly warm\u0026#34; local orange = oklab_to_srgb(0.68, 0.055, 0.065) That first number is brightness (0-1). The next two control hue and saturation. Want it brighter? Increase the first number. Want it more orange? Adjust the ratio. It\u0026rsquo;s predictable in a way hex codes never were.\nPart 2: What Actually Needs to be Colorful? Here\u0026rsquo;s where I made my first big mistake. I used to color everything‚Äîvariables, operators, you name it. Turns out, that\u0026rsquo;s probably wrong.\nI found this 2018 study with 390 programming beginners. The surprising finding? Syntax highlighting doesn\u0026rsquo;t really help with understanding code. But wait‚Äîit does help when it emphasizes structural elements rather than coloring everything equally.\nThe takeaway: Highlight structure, not noise.\nThen I read Ivan Tonsky\u0026rsquo;s article where he points out that most of your code is variables and function calls. If you highlight all of those, you\u0026rsquo;re coloring like 75% of the screen. No wonder everything looks busy!\nHis suggestion made so much sense: keep variables and operators neutral (same color as regular text). Only use bright colors for the stuff that actually matters.\nMy New Three-Tier System This research led me to a much simpler approach:\nBright colors for the important bits:\nControl flow (if, for, while, return) Function definitions Type declarations Regular text color for the rest:\nVariable names Operators Function parameters Dimmed colors for secondary stuff:\nComments Delimiters The result is subtle but effective. The code\u0026rsquo;s structure jumps out at you, but most of the screen stays calm and readable.\nPart 3: Brightness is Everything (Seriously) This was my biggest \u0026ldquo;aha\u0026rdquo; moment. I used to spend hours debating whether keywords should be orange or yellow. Turns out, I was asking the wrong question.\nHuman eyes are way more sensitive to brightness differences than to color differences. Like, 5-10 times more sensitive. There\u0026rsquo;s actual science behind this called the \u0026ldquo;Contrast Sensitivity Function.\u0026rdquo;\nSo the real question isn\u0026rsquo;t \u0026ldquo;what color should this be?\u0026rdquo; It\u0026rsquo;s \u0026ldquo;how bright should this be compared to that?\u0026rdquo;\nBuilding a Brightness Hierarchy That Actually Works I started with some basic constraints:\nBackground: L=0.24 (dark enough to be comfortable at night) Regular text: L=0.74 (great contrast, meets accessibility standards) From the research, I knew structure was most important, errors needed attention, and data was secondary. So I made three brightness levels:\nBrightest (L=0.68): Structure elements (keywords, functions, types) Middle (L=0.66): Errors and warnings Dimmest (L=0.64): Data (strings, numbers, constants) The math checks out for contrast ratios: CR(L1,Lbg)=0.68+0.050.24+0.05=5.52:1CR(L2,Lbg)=0.66+0.050.24+0.05=5.03:1CR(L3,Lbg)=0.64+0.050.24+0.05=4.76:1 \\begin{aligned} \\text{CR}(L_1, L_{\\text{bg}}) \u0026amp;= \\frac{0.68 + 0.05}{0.24 + 0.05} = 5.52:1 \\\\ \\text{CR}(L_2, L_{\\text{bg}}) \u0026amp;= \\frac{0.66 + 0.05}{0.24 + 0.05} = 5.03:1 \\\\ \\text{CR}(L_3, L_{\\text{bg}}) \u0026amp;= \\frac{0.64 + 0.05}{0.24 + 0.05} = 4.76:1 \\end{aligned} CR(L1‚Äã,Lbg‚Äã)CR(L2‚Äã,Lbg‚Äã)CR(L3‚Äã,Lbg‚Äã)‚Äã=0.24+0.050.68+0.05‚Äã=5.52:1=0.24+0.050.66+0.05‚Äã=5.03:1=0.24+0.050.64+0.05‚Äã=4.76:1‚ÄãAll three meet WCAG AA standards, and the brightness differences (ŒîL=0.02) are noticeable without being jarring.\nHere\u0026rsquo;s what\u0026rsquo;s cool: in my old themes, errors were the same brightness as strings. No wonder I\u0026rsquo;d miss them! Now errors stand out just enough to catch my attention without looking like an alarm went off.\nThe Complete Brightness System Level Brightness Use For Why It Works 1 L=0.68 Keywords, Functions, Types Guides your eye to the code\u0026rsquo;s structure 2 L=0.66 Errors, Warnings Noticeable but not overwhelming 3 L=0.64 Strings, Numbers, Constants Stays in the background - L=0.24 Background Easy on the eyes - L=0.74 Regular text Maximum readability Part 4: The Fatigue Factor Here\u0026rsquo;s something I never considered: different colors actually cause different amounts of eye strain. Red wavelengths are the worst‚Äîthey make your pupils constrict more, which gets tiring. Yellow is the easiest on your eyes.\nThere\u0026rsquo;s research (they measure pupil response and everything) that shows for comfortable long sessions, you want to keep colors muted:\nAverage saturation around 0.08 Red saturation under 0.09 Yellow/green under 0.10 In Oklab, saturation is simple: s=a2+b2 s = \\sqrt{a^2 + b^2} s=a2+b2‚ÄãSo I made sure all my colors stayed in the safe zone:\n-- Orange for keywords: ‚àö(0.055¬≤ + 0.065¬≤) ‚âà 0.085 colors.orange = oklab_to_srgb(0.68, 0.055, 0.065) -- Red for errors: ‚àö(0.08¬≤ + 0.04¬≤) ‚âà 0.089 (just under 0.09) colors.red = oklab_to_srgb(0.66, 0.08, 0.04) -- Yellow for types: ‚àö(0.02¬≤ + 0.08¬≤) ‚âà 0.082 colors.yellow = oklab_to_srgb(0.68, 0.02, 0.08) No more wondering why my eyes hurt after a marathon coding session.\nPart 5: What Colors \u0026ldquo;Mean\u0026rdquo; Colors aren\u0026rsquo;t just pretty‚Äîthey carry associations. Research shows we tend to agree on what colors mean:\nRed ‚Üí Error, Danger, Stop Orange ‚Üí Action, Warning, Warm Yellow ‚Üí Important, Attention Green ‚Üí Success, Natural, Content Blue ‚Üí Logic, Stability, Cool Cyan ‚Üí Technical, Meta Violet ‚Üí Abstract, Special This gave me a logical way to assign colors:\nCode Element Why This Color Oklab Values Keywords Action ‚Üí Orange (0.68, 0.055, 0.065) Functions Logic ‚Üí Blue (0.68, -0.02, -0.06) Types Important ‚Üí Yellow (0.68, 0.02, 0.08) Errors Danger ‚Üí Red (0.66, 0.08, 0.04) Strings Content ‚Üí Green (0.64, -0.05, 0.06) Constants Technical ‚Üí Cyan (0.64, -0.055, -0.01) Numbers Abstract ‚Üí Violet (0.64, 0.05, -0.04) Putting It All Together Here\u0026rsquo;s the final palette. Every value comes from those principles, not random guesses:\nlocal colors = {} -- Background and text colors.bg = oklab_to_srgb(0.24, 0.001, 0.006) colors.fg = oklab_to_srgb(0.74, 0.0, 0.008) -- Layer 1: Structure (brightest) colors.orange = oklab_to_srgb(0.68, 0.055, 0.065) -- Keywords colors.blue = oklab_to_srgb(0.68, -0.02, -0.06) -- Functions colors.yellow = oklab_to_srgb(0.68, 0.02, 0.08) -- Types -- Layer 2: Diagnostics colors.red = oklab_to_srgb(0.66, 0.08, 0.04) -- Errors -- Layer 3: Data colors.green = oklab_to_srgb(0.64, -0.05, 0.06) -- Strings colors.cyan = oklab_to_srgb(0.64, -0.055, -0.01) -- Constants colors.violet = oklab_to_srgb(0.64, 0.05, -0.04) -- Numbers return colors And the highlight groups:\n-- Important stuff (bright) vim.api.nvim_set_hl(0, \u0026#39;Keyword\u0026#39;, { fg = colors.orange }) vim.api.nvim_set_hl(0, \u0026#39;Function\u0026#39;, { fg = colors.blue }) vim.api.nvim_set_hl(0, \u0026#39;Type\u0026#39;, { fg = colors.yellow }) -- Less important (dimmer) vim.api.nvim_set_hl(0, \u0026#39;String\u0026#39;, { fg = colors.green }) vim.api.nvim_set_hl(0, \u0026#39;Constant\u0026#39;, { fg = colors.cyan }) vim.api.nvim_set_hl(0, \u0026#39;Number\u0026#39;, { fg = colors.violet }) -- Neutral (same as regular text) vim.api.nvim_set_hl(0, \u0026#39;Identifier\u0026#39;, { fg = colors.fg }) -- Variables vim.api.nvim_set_hl(0, \u0026#39;Operator\u0026#39;, { fg = colors.fg }) -- =, +, -, etc. Does It Actually Work? Don\u0026rsquo;t doubt it, this is still neovim üòè. I\u0026rsquo;ve been using this theme (I call it Retina) for two months now. Here\u0026rsquo;s what I\u0026rsquo;ve noticed:\nMy eyes don\u0026rsquo;t get tired anymore. I can code for hours without that strained feeling. Errors actually stand out. That slight brightness bump makes all the difference. I can see the code\u0026rsquo;s structure immediately. My eyes naturally follow the bright keywords. It\u0026rsquo;s\u0026hellip; quiet. With most variables staying neutral, there\u0026rsquo;s way less visual noise. A Quick Reality Check Look, vision is personal. This works for me, but your eyes might be different. Things that matter:\nYour age (older eyes often need more contrast) Your monitor (OLED vs LCD, different calibrations) Your environment (dark room vs bright office) Your color vision (about 8% of men see colors differently) The beauty of this approach is you can adjust the parameters instead of guessing:\n-- Need more contrast? Bump up the brightness: colors.orange = oklab_to_srgb(0.70, 0.055, 0.065) -- Was 0.68 -- Colors too strong? Tone down the saturation: colors.orange = oklab_to_srgb(0.68, 0.044, 0.052) -- 20% less saturation -- Want different hues? Adjust the a,b ratio: colors.orange = oklab_to_srgb(0.68, 0.050, 0.070) -- More yellow You\u0026rsquo;re tuning a system, not just picking random colors.\nThe best theme really is the one you forget you\u0026rsquo;re using. It just gets out of your way and lets you focus on the code.\nReferences \u0026amp; Further Reading Oklab color space: https://bottosson.github.io/posts/oklab/ Contrast Sensitivity Function: Barten, P. G. J. (1999) Color Appearance Models: Fairchild, M. D. (2013) Visual Fatigue Study: Fan et al. (2024) Color Semantics: Schloss, K. B. (2024) Vision and Aging: Owsley, C. (2016) Syntax Highlighting Research: Hannebauer et al. (2018) \u0026ldquo;Syntax Highlighting is a Waste of Time\u0026rdquo;: https://tonsky.me/blog/syntax-highlighting/ You can find the complete theme on GitHub. Use it, tweak it, or just steal the ideas for your own theme. Either way, I hope it helps you break out of the endless theme-tweaking cycle.\n","date":"2025-12-24","permalink":"https://www.functor.me/posts/colorscheme/","section":"","summary":"","tags":["","","",""],"title":"The Best Theme Isn't the Prettiest‚ÄîIt's the One You Forget Exists"}]